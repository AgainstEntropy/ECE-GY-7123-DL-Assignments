\noindent \textred{2.} 
\textbf{(3 points)} \textit{Understanding self-attention}. Let us assume the basic definition of self-attention (without any weight matrices), where all the queries, keys, and values are the data points themselves (\ie, $x_i = q_i = k_i = v_i$). We will see how self-attention lets the network select different parts of the data to be the ``content" (value) and other parts to determine where to ``pay attention" (queries and keys).
Consider 4 orthogonal ``base‚Äù vectors all of equal $\ell_2$ norm $a, b, c, d$. (Suppose that their norm is $\beta$, which is some very, very large number.) Out of these base vectors, construct 3 tokens:
\begin{align*}
    x_1 &= d + b, \\
    x_2 &= a, \\
    x_3 &= c + b.
\end{align*}
\begin{enumerate}[a.]
    \item (0.5 points) What are the norms of $x_1, x_2, x_3$?
    \myAnswer{
    \begin{align*}
        || x_1 ||_2 &= \sqrt{x_1 \cdot x_1} = \sqrt{(d+b) \cdot (d+b)} = \sqrt{d^2 + b^2} = \sqrt{2} \beta \\
        || x_2 ||_2 &= \sqrt{x_2 \cdot x_2} = \beta \\
        || x_3 ||_2 &= \sqrt{x_3 \cdot x_3} = \sqrt{2} \beta
    \end{align*}
    }
    \item (2 points) Compute $(y_1, y_2, y_3)$ = Self-attention $(x_1, x_2, x_3)$. Identify which tokens (or combinations of tokens) are approximated by the outputs $y_1, y_2, y_3$. \\
    \myAnswer{
    To compute the result of Self-attention operation, we first compute the dot-product result
    \[
        w_{ij} = q_i^T \cdot k_j = x_i^T \cdot x_j
        \quad \Longrightarrow \quad
        w = \left(
        \begin{array}{ccc}
            2 \beta^2 & 0 & \beta^2 \\
            0 & \beta^2 & 0 \\
            \beta^2 & 0 & 2 \beta^2
        \end{array}
        \right).
    \]
    Then we can calculated the attention map after Softmax operation
    \[
        W = \mathrm{Softmax}(w) = 
        \left(
        \begin{array}{ccc}
            \frac{1}{1 + e^{-\beta^2}} & 0 & \frac{1}{1 + e^{\beta^2}} \\
            0 & 1 & 0 \\
            \frac{1}{1 + e^{\beta^2}} & 0 & \frac{1}{1 + e^{-\beta^2}}
        \end{array}
        \right)
        \approx
        \left(
        \begin{array}{ccc}
            1 - \alpha & 0 & \alpha \\
            0 & 1 & 0 \\
            \alpha & 0 & 1 - \alpha
        \end{array}
        \right),
    \]
    where $\alpha = e^{-\beta^2}$ is a very small number. The above approximation is due to the very large $\beta$. Then we can compute the final outputs as
    \[
        y_i = \sum_j W_{ij} v_j \Longrightarrow (y_1, y_2, y_3) \approx (d+b+\alpha(c-d), a, c+b+\alpha(d-c)) \approx (x_1, x_2, x_3).
    \]
    Therefore, the outputs actually approximate the original input tokens.
    }
    \item (0.5 points) Using the above example, describe in a couple of sentences how self-attention that allows networks to approximately ``copy" an input value to the output. \\
    \myAnswer{
    If one token has very small similarity (measured with cosine similarity or dot-product similarity), in attention map this token will be assigned very small scores with all other tokens. Thus, this token will be approximately ``copied" from input to output.
    }
\end{enumerate}